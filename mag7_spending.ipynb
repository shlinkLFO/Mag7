{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f398d06",
   "metadata": {},
   "source": [
    "# MAG7 Spending Data Analysis\n",
    "## Comprehensive Summary Statistics and Gap Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d696f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Companies in dataset: ['Apple', 'Microsoft', 'Alphabet', 'Amazon', 'NVIDIA', 'Tesla', 'Meta']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the data\n",
    "with open('mag7_spending.json', 'r', encoding='utf-8') as f:\n",
    "    mag7_data = json.load(f)\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Companies in dataset: {list(mag7_data.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bbc60",
   "metadata": {},
   "source": [
    "## 1. Data Structure Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b4a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique domains: 34\n",
      "\n",
      "Domains: ['5g_6g_network_infrastructure', 'ai_efficiency_methods', 'ai_foundation_models', 'autonomous_mobility', 'batteries_and_storage', 'bio_ai_and_drug_discovery', 'circularity_reuse_recycling', 'cloud_data_centers_ai_infra', 'content_production_studios', 'digital_health_devices', 'digital_inclusion_and_economy', 'diversity_equity_inclusion', 'edge_computing_infrastructure', 'gaming_platforms_engines', 'industrial_automation_supply_chain', 'litigation_settlements_fines', 'mergers_and_acquisitions', 'quantum_computing', 'r_and_d', 'regulatory_compliance_investments', 'renewable_energy_generation', 'responsible_ai_safety_governance', 'robotics_autonomy', 'satellite_and_subsea_infrastructure', 'sci_fi_consumer_devices', 'security_cryptography', 'semiconductor_ai_hardware', 'share_repurchases', 'strategic_investments', 'superconducting_devices_squids', 'supply_chain_digitization', 'wellness_vr_and_behavioral', 'workforce_training_reskilling', 'xr_metaverse_and_spatial_computing']\n",
      "\n",
      "Total records per company:\n",
      "  Alphabet: 65 records\n",
      "  Microsoft: 63 records\n",
      "  Amazon: 59 records\n",
      "  Apple: 58 records\n",
      "  Meta: 47 records\n",
      "  NVIDIA: 44 records\n",
      "  Tesla: 32 records\n"
     ]
    }
   ],
   "source": [
    "# Get all unique domains\n",
    "all_domains = set()\n",
    "for company_data in mag7_data.values():\n",
    "    all_domains.update(company_data.keys())\n",
    "\n",
    "print(f\"Total unique domains: {len(all_domains)}\")\n",
    "print(f\"\\nDomains: {sorted(all_domains)}\")\n",
    "\n",
    "# Count records per company\n",
    "record_counts = {}\n",
    "for company, domains in mag7_data.items():\n",
    "    total_records = sum(len(records) for records in domains.values())\n",
    "    record_counts[company] = total_records\n",
    "\n",
    "print(f\"\\nTotal records per company:\")\n",
    "for company, count in sorted(record_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {company}: {count} records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d7a3b5",
   "metadata": {},
   "source": [
    "## 2. Total Spending by Company\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7687c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOTAL SPENDING BY COMPANY ===\n",
      "           total_billions  records_with_amount  records_null_amount  percent_documented\n",
      "Apple             1820.95                 41.0                 17.0                70.7\n",
      "Alphabet           602.48                 47.0                 18.0                72.3\n",
      "Microsoft          513.55                 50.0                 13.0                79.4\n",
      "Meta               358.61                 35.0                 12.0                74.5\n",
      "Amazon             259.54                 44.0                 15.0                74.6\n",
      "NVIDIA             170.26                 38.0                  6.0                86.4\n",
      "Tesla               32.89                 23.0                  9.0                71.9\n",
      "\n",
      "Grand Total: $3758.28B\n",
      "Average documentation rate: 75.7%\n"
     ]
    }
   ],
   "source": [
    "def calculate_company_spending(company_name):\n",
    "    \"\"\"Calculate total documented spending for a company\"\"\"\n",
    "    total = 0\n",
    "    count_with_amount = 0\n",
    "    count_null = 0\n",
    "    \n",
    "    for domain, records in mag7_data[company_name].items():\n",
    "        for record in records:\n",
    "            amount = record.get('investment_amount_billions_usd')\n",
    "            if amount is not None and isinstance(amount, (int, float)):\n",
    "                total += amount\n",
    "                count_with_amount += 1\n",
    "            else:\n",
    "                count_null += 1\n",
    "    \n",
    "    return {\n",
    "        'total_billions': round(total, 2),\n",
    "        'records_with_amount': count_with_amount,\n",
    "        'records_null_amount': count_null,\n",
    "        'percent_documented': round(count_with_amount / (count_with_amount + count_null) * 100, 1) if (count_with_amount + count_null) > 0 else 0\n",
    "    }\n",
    "\n",
    "company_spending = {}\n",
    "for company in mag7_data.keys():\n",
    "    company_spending[company] = calculate_company_spending(company)\n",
    "\n",
    "# Create DataFrame\n",
    "df_company_spending = pd.DataFrame(company_spending).T\n",
    "df_company_spending = df_company_spending.sort_values('total_billions', ascending=False)\n",
    "\n",
    "print(\"\\n=== TOTAL SPENDING BY COMPANY ===\")\n",
    "print(df_company_spending.to_string())\n",
    "print(f\"\\nGrand Total: ${df_company_spending['total_billions'].sum():.2f}B\")\n",
    "print(f\"Average documentation rate: {df_company_spending['percent_documented'].mean():.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0887",
   "metadata": {},
   "source": [
    "## 3. Spending by Domain (Aggregated Across All Companies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8467b382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 20 DOMAINS BY TOTAL SPENDING ===\n",
      "                             domain  total_billions  total_records  with_amount  null_amount  companies_count  documentation_rate\n",
      "                  share_repurchases         1717.47             60           60            0                7               100.0\n",
      "      digital_inclusion_and_economy          988.50             10           10            0                5               100.0\n",
      "        cloud_data_centers_ai_infra          239.33             36           34            2                7                94.4\n",
      " xr_metaverse_and_spatial_computing          168.96             10            9            1                3                90.0\n",
      "         content_production_studios          159.20              8            7            1                4                87.5\n",
      "               ai_foundation_models           79.64             25           23            2                6                92.0\n",
      "                autonomous_mobility           68.49             13           13            0                6               100.0\n",
      "        renewable_energy_generation           55.45             59           12           47                7                20.3\n",
      "       litigation_settlements_fines           50.01             11           11            0                4               100.0\n",
      "              security_cryptography           35.40              7            3            4                6                42.9\n",
      "           mergers_and_acquisitions           33.40              3            3            0                2               100.0\n",
      "satellite_and_subsea_infrastructure           28.14             10            9            1                4                90.0\n",
      "             digital_health_devices           23.60              3            2            1                3                66.7\n",
      " industrial_automation_supply_chain           18.58              8            7            1                3                87.5\n",
      "           gaming_platforms_engines           15.98              4            3            1                2                75.0\n",
      "              batteries_and_storage           14.06             14           11            3                5                78.6\n",
      "          semiconductor_ai_hardware           13.25             10            9            1                7                90.0\n",
      "          supply_chain_digitization           11.00              2            2            0                1               100.0\n",
      "              strategic_investments            9.31             13           11            2                3                84.6\n",
      "              ai_efficiency_methods            8.80             11            5            6                7                45.5\n",
      "\n",
      "=== DOMAINS WITH LOWEST DOCUMENTATION RATES ===\n",
      "                          domain  total_records  documentation_rate\n",
      "  superconducting_devices_squids              1                 0.0\n",
      "                         r_and_d              0                 0.0\n",
      "     renewable_energy_generation             59                20.3\n",
      "responsible_ai_safety_governance              3                33.3\n",
      "           security_cryptography              7                42.9\n",
      "           ai_efficiency_methods             11                45.5\n",
      "     circularity_reuse_recycling             11                45.5\n",
      "               robotics_autonomy             10                60.0\n",
      "               quantum_computing              5                60.0\n",
      "          digital_health_devices              3                66.7\n"
     ]
    }
   ],
   "source": [
    "def calculate_domain_spending():\n",
    "    \"\"\"Calculate spending by domain across all companies\"\"\"\n",
    "    domain_stats = defaultdict(lambda: {\n",
    "        'total_billions': 0,\n",
    "        'record_count': 0,\n",
    "        'records_with_amount': 0,\n",
    "        'records_null': 0,\n",
    "        'companies_active': set()\n",
    "    })\n",
    "    \n",
    "    for company, domains in mag7_data.items():\n",
    "        for domain, records in domains.items():\n",
    "            domain_stats[domain]['companies_active'].add(company)\n",
    "            for record in records:\n",
    "                domain_stats[domain]['record_count'] += 1\n",
    "                amount = record.get('investment_amount_billions_usd')\n",
    "                if amount is not None and isinstance(amount, (int, float)):\n",
    "                    domain_stats[domain]['total_billions'] += amount\n",
    "                    domain_stats[domain]['records_with_amount'] += 1\n",
    "                else:\n",
    "                    domain_stats[domain]['records_null'] += 1\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    rows = []\n",
    "    for domain, stats in domain_stats.items():\n",
    "        rows.append({\n",
    "            'domain': domain,\n",
    "            'total_billions': round(stats['total_billions'], 2),\n",
    "            'total_records': stats['record_count'],\n",
    "            'with_amount': stats['records_with_amount'],\n",
    "            'null_amount': stats['records_null'],\n",
    "            'companies_count': len(stats['companies_active']),\n",
    "            'documentation_rate': round(stats['records_with_amount'] / stats['record_count'] * 100, 1) if stats['record_count'] > 0 else 0\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_domain_spending = calculate_domain_spending()\n",
    "df_domain_spending = df_domain_spending.sort_values('total_billions', ascending=False)\n",
    "\n",
    "print(\"\\n=== TOP 20 DOMAINS BY TOTAL SPENDING ===\")\n",
    "print(df_domain_spending.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n=== DOMAINS WITH LOWEST DOCUMENTATION RATES ===\")\n",
    "print(df_domain_spending.nsmallest(10, 'documentation_rate')[['domain', 'total_records', 'documentation_rate']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f688375",
   "metadata": {},
   "source": [
    "## 8. Capex Type & Tech Breakdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454c1fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CAPEX TYPE & TECH BREAKDOWN (BY COMPANY) ===\n",
      "\n",
      "Apple:\n",
      "                   Capex Type - Tech  Total Billions USD  Record Count\n",
      " Growth - Manufacturing & Production              500.00             1\n",
      "     Growth - Digital Infrastructure               10.00             1\n",
      "                      Growth - Other                4.70             1\n",
      "       Growth - Corporate Facilities                2.00             2\n",
      "Maintenance - Digital Infrastructure                0.45             1\n",
      "\n",
      "Microsoft:\n",
      "              Capex Type - Tech  Total Billions USD  Record Count\n",
      "Growth - Digital Infrastructure               24.63             8\n",
      "                 Growth - Other                0.16             1\n",
      "\n",
      "Alphabet:\n",
      "              Capex Type - Tech  Total Billions USD  Record Count\n",
      "Growth - Digital Infrastructure                23.5             3\n",
      "                 Growth - Other                 0.6             1\n",
      "\n",
      "Amazon:\n",
      "               Capex Type - Tech  Total Billions USD  Record Count\n",
      " Growth - Digital Infrastructure              171.04            12\n",
      "                  Growth - Other               12.01             2\n",
      "Growth - Logistics & Fulfillment                1.00             1\n",
      "\n",
      "NVIDIA:\n",
      "               Capex Type - Tech  Total Billions USD  Record Count\n",
      "                  Growth - Other                2.46             4\n",
      "Growth - Logistics & Fulfillment                0.98             1\n",
      "   Growth - Corporate Facilities                0.92             1\n",
      " Growth - Digital Infrastructure                0.10             1\n",
      "\n",
      "Tesla:\n",
      "                  Capex Type - Tech  Total Billions USD  Record Count\n",
      "Growth - Manufacturing & Production               11.00             5\n",
      "    Growth - Digital Infrastructure                3.00             4\n",
      "                     Growth - Other                0.56             1\n",
      "\n",
      "Meta:\n",
      "              Capex Type - Tech  Total Billions USD  Record Count\n",
      "Growth - Digital Infrastructure               15.84             6\n",
      "                 Growth - Other               10.00             1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def analyze_capex_breakdown():\n",
    "    \"\"\"Analyze capex spending by capex_type and capex_tech for each company.\"\"\"\n",
    "    capex_data = defaultdict(lambda: defaultdict(lambda: {'total_billions': 0, 'record_count': 0}))\n",
    "\n",
    "    for company, domains in mag7_data.items():\n",
    "        for domain, records in domains.items():\n",
    "            for record in records:\n",
    "                if record.get('spend_type') == 'capex':\n",
    "                    capex_type = record.get('capex_type', 'unspecified_type')\n",
    "                    capex_tech = record.get('capex_tech', 'unspecified_tech')\n",
    "                    amount = record.get('investment_amount_billions_usd')\n",
    "\n",
    "                    if amount is not None and isinstance(amount, (int, float)):\n",
    "                        key = f\"{capex_type} - {capex_tech}\"\n",
    "                        capex_data[company][key]['total_billions'] += amount\n",
    "                        capex_data[company][key]['record_count'] += 1\n",
    "    \n",
    "    # Format for display\n",
    "    company_capex_summary = {}\n",
    "    for company, types in capex_data.items():\n",
    "        rows = []\n",
    "        for key, stats in types.items():\n",
    "            rows.append({\n",
    "                'Capex Type - Tech': key,\n",
    "                'Total Billions USD': round(stats['total_billions'], 2),\n",
    "                'Record Count': stats['record_count']\n",
    "            })\n",
    "        company_capex_summary[company] = pd.DataFrame(rows).sort_values(by='Total Billions USD', ascending=False)\n",
    "    \n",
    "    return company_capex_summary\n",
    "\n",
    "company_capex_breakdowns = analyze_capex_breakdown()\n",
    "\n",
    "capex_rollup_rows = []\n",
    "for company, df_capex in company_capex_breakdowns.items():\n",
    "    for _, row in df_capex.iterrows():\n",
    "        type_tech = row['Capex Type - Tech']\n",
    "        if ' - ' in type_tech:\n",
    "            capex_type, capex_tech = type_tech.split(' - ', 1)\n",
    "        else:\n",
    "            capex_type = type_tech\n",
    "            capex_tech = 'Other'\n",
    "        capex_rollup_rows.append({\n",
    "            'company': company,\n",
    "            'capex_type': capex_type,\n",
    "            'capex_tech': capex_tech,\n",
    "            'total_billions': row['Total Billions USD'],\n",
    "            'record_count': row['Record Count']\n",
    "        })\n",
    "\n",
    "df_capex_rollup = pd.DataFrame(capex_rollup_rows)\n",
    "df_capex_type_totals = pd.DataFrame()\n",
    "if not df_capex_rollup.empty:\n",
    "    df_capex_type_totals = (df_capex_rollup\n",
    "        .groupby(['company', 'capex_type'], as_index=False)\n",
    "        .agg({'total_billions': 'sum', 'record_count': 'sum'})\n",
    "        .sort_values(['company', 'total_billions'], ascending=[True, False]))\n",
    "\n",
    "print(\"\\n=== CAPEX TYPE & TECH BREAKDOWN (BY COMPANY) ===\")\n",
    "\n",
    "for company, df_capex in company_capex_breakdowns.items():\n",
    "    if not df_capex.empty:\n",
    "        print(f\"\\n{company}:\")\n",
    "        print(df_capex.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"\\n{company}: No capex records found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891fb807",
   "metadata": {},
   "source": [
    "## 9. Opex Type Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f1a989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPEX TYPE BREAKDOWN (BY COMPANY) ===\n",
      "\n",
      "Apple:\n",
      "       Opex Type  Total Billions USD  Record Count\n",
      "             R&D               491.2             5\n",
      "           Other                26.9             3\n",
      "Legal Settlement                16.5             1\n",
      "\n",
      "Microsoft:\n",
      "Opex Type  Total Billions USD  Record Count\n",
      "      R&D               20.00             1\n",
      "    Other                1.62             4\n",
      " COR/COGS                0.98             1\n",
      "\n",
      "Alphabet:\n",
      "       Opex Type  Total Billions USD  Record Count\n",
      "             R&D               31.00             2\n",
      "        COR/COGS               30.00             1\n",
      "Legal Settlement               26.35             6\n",
      "           Other               10.18             2\n",
      "\n",
      "Amazon:\n",
      "Opex Type  Total Billions USD  Record Count\n",
      "    Other               24.10             3\n",
      "      S&M                0.15             1\n",
      "      R&D                0.11             1\n",
      "\n",
      "NVIDIA:\n",
      "Opex Type  Total Billions USD  Record Count\n",
      "      R&D               17.02             3\n",
      "    Other                1.64             1\n",
      "\n",
      "Tesla:\n",
      "       Opex Type  Total Billions USD  Record Count\n",
      "             R&D                3.97             1\n",
      "Legal Settlement                0.02             1\n",
      "\n",
      "Meta:\n",
      "       Opex Type  Total Billions USD  Record Count\n",
      "             R&D              113.47             6\n",
      "Legal Settlement                7.14             3\n",
      "           Other                0.20             1\n",
      "             G&A                0.03             1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def analyze_opex_breakdown():\n",
    "    \"\"\"Analyze opex spending by opex_type for each company.\"\"\"\n",
    "    opex_data = defaultdict(lambda: defaultdict(lambda: {'total_billions': 0, 'record_count': 0}))\n",
    "\n",
    "    for company, domains in mag7_data.items():\n",
    "        for domain, records in domains.items():\n",
    "            for record in records:\n",
    "                if record.get('spend_type') == 'opex':\n",
    "                    opex_type = record.get('opex_type', 'unspecified_type')\n",
    "                    amount = record.get('investment_amount_billions_usd')\n",
    "\n",
    "                    if amount is not None and isinstance(amount, (int, float)):\n",
    "                        opex_data[company][opex_type]['total_billions'] += amount\n",
    "                        opex_data[company][opex_type]['record_count'] += 1\n",
    "    \n",
    "    # Format for display\n",
    "    company_opex_summary = {}\n",
    "    for company, types in opex_data.items():\n",
    "        rows = []\n",
    "        for key, stats in types.items():\n",
    "            rows.append({\n",
    "                'Opex Type': key,\n",
    "                'Total Billions USD': round(stats['total_billions'], 2),\n",
    "                'Record Count': stats['record_count']\n",
    "            })\n",
    "        company_opex_summary[company] = pd.DataFrame(rows).sort_values(by='Total Billions USD', ascending=False)\n",
    "    \n",
    "    return company_opex_summary\n",
    "\n",
    "ope_capex_breakdowns = analyze_opex_breakdown()\n",
    "\n",
    "opex_rollup_rows = []\n",
    "for company, df_opex in ope_capex_breakdowns.items():\n",
    "    for _, row in df_opex.iterrows():\n",
    "        opex_rollup_rows.append({\n",
    "            'company': company,\n",
    "            'opex_type': row['Opex Type'],\n",
    "            'total_billions': row['Total Billions USD'],\n",
    "            'record_count': row['Record Count']\n",
    "        })\n",
    "\n",
    "df_opex_rollup = pd.DataFrame(opex_rollup_rows)\n",
    "df_opex_type_totals = pd.DataFrame()\n",
    "if not df_opex_rollup.empty:\n",
    "    df_opex_type_totals = (df_opex_rollup\n",
    "        .groupby(['company', 'opex_type'], as_index=False)\n",
    "        .agg({'total_billions': 'sum', 'record_count': 'sum'})\n",
    "        .sort_values(['company', 'total_billions'], ascending=[True, False]))\n",
    "\n",
    "print(\"\\n=== OPEX TYPE BREAKDOWN (BY COMPANY) ===\")\n",
    "\n",
    "for company, df_opex in ope_capex_breakdowns.items():\n",
    "    if not df_opex.empty:\n",
    "        print(f\"\\n{company}:\")\n",
    "        print(df_opex.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"\\n{company}: No opex records found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e9a5a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ceff4",
   "metadata": {},
   "source": [
    "## 4. Spending by Type (Aggregated by Company)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ac5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SPENDING BY TYPE (BY COMPANY) ===\n",
      "\n",
      "Alphabet:\n",
      "spend_type  total_billions  record_count\n",
      "    equity          429.93            26\n",
      "      opex           97.52            14\n",
      "       M&A           41.73             6\n",
      "     capex           24.10             7\n",
      "       ppa            9.20            12\n",
      "\n",
      "Amazon:\n",
      "spend_type  total_billions  record_count\n",
      "     capex          184.05            16\n",
      "       M&A           28.88             7\n",
      "      opex           24.36             7\n",
      "    equity           22.25            18\n",
      "       ppa            0.00            11\n",
      "\n",
      "Apple:\n",
      "spend_type  total_billions  record_count\n",
      "    equity          763.70            20\n",
      "      opex          534.60            14\n",
      "     capex          517.15             7\n",
      "       M&A            4.90            10\n",
      "       ppa            0.60             7\n",
      "\n",
      "Meta:\n",
      "spend_type  total_billions  record_count\n",
      "    equity          194.83            13\n",
      "      opex          120.84            13\n",
      "     capex           25.84            12\n",
      "       ppa           14.20             5\n",
      "       M&A            2.90             4\n",
      "\n",
      "Microsoft:\n",
      "spend_type  total_billions  record_count\n",
      "    equity          310.36            26\n",
      "       M&A          145.80             8\n",
      "     capex           24.79             9\n",
      "      opex           22.60             8\n",
      "       ppa           10.00            12\n",
      "\n",
      "NVIDIA:\n",
      "spend_type  total_billions  record_count\n",
      "    equity          137.75            22\n",
      "      opex           18.66             7\n",
      "       M&A            9.40             5\n",
      "     capex            4.46             8\n",
      "       ppa            0.00             2\n",
      "\n",
      "Tesla:\n",
      "spend_type  total_billions  record_count\n",
      "     capex           14.56            14\n",
      "       M&A           12.84             8\n",
      "      opex            3.99             5\n",
      "    equity            1.50             4\n",
      "       ppa            0.00             1\n",
      "\n",
      "=== AGGREGATE SPENDING BY TYPE (ALL COMPANIES) ===\n",
      "            total_billions  record_count\n",
      "spend_type                              \n",
      "equity             1860.32           129\n",
      "opex                822.57            68\n",
      "capex               794.95            73\n",
      "M&A                 246.45            48\n",
      "ppa                  34.00            50\n"
     ]
    }
   ],
   "source": [
    "def analyze_spending_types():\n",
    "    \"\"\"Analyze spending by spend_type for each company\"\"\"\n",
    "    company_type_spending = defaultdict(lambda: defaultdict(lambda: {'amount': 0, 'count': 0}))\n",
    "    \n",
    "    for company, domains in mag7_data.items():\n",
    "        for domain, records in domains.items():\n",
    "            for record in records:\n",
    "                spend_type = record.get('spend_type') or 'unspecified'\n",
    "                amount = record.get('investment_amount_billions_usd')\n",
    "                \n",
    "                company_type_spending[company][spend_type]['count'] += 1\n",
    "                if amount is not None and isinstance(amount, (int, float)):\n",
    "                    company_type_spending[company][spend_type]['amount'] += amount\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    rows = []\n",
    "    for company, types in company_type_spending.items():\n",
    "        for spend_type, stats in types.items():\n",
    "            rows.append({\n",
    "                'company': company,\n",
    "                'spend_type': spend_type,\n",
    "                'total_billions': round(stats['amount'], 2),\n",
    "                'record_count': stats['count']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_spending_types = analyze_spending_types()\n",
    "\n",
    "print(\"\\n=== SPENDING BY TYPE (BY COMPANY) ===\")\n",
    "for company in sorted(mag7_data.keys()):\n",
    "    company_data = df_spending_types[df_spending_types['company'] == company]\n",
    "    if not company_data.empty:\n",
    "        print(f\"\\n{company}:\")\n",
    "        print(company_data[['spend_type', 'total_billions', 'record_count']].sort_values('total_billions', ascending=False).to_string(index=False))\n",
    "\n",
    "# Aggregate by type across all companies\n",
    "type_totals = df_spending_types.groupby('spend_type').agg({\n",
    "    'total_billions': 'sum',\n",
    "    'record_count': 'sum'\n",
    "}).sort_values('total_billions', ascending=False)\n",
    "\n",
    "print(\"\\n=== AGGREGATE SPENDING BY TYPE (ALL COMPANIES) ===\")\n",
    "print(type_totals.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076cd88",
   "metadata": {},
   "source": [
    "## 5. Temporal Analysis (Spending by Year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b24153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SPENDING BY YEAR ===\n",
      " year  total_billions  record_count\n",
      " 2014            2.97             2\n",
      " 2015           15.30             5\n",
      " 2016           54.13            10\n",
      " 2017           70.18            12\n",
      " 2018          140.68            20\n",
      " 2019          143.60            26\n",
      " 2020          218.83            31\n",
      " 2021          696.57            36\n",
      " 2022          298.20            26\n",
      " 2023          436.60            49\n",
      " 2024          432.91            79\n",
      " 2025         1142.12            63\n",
      " 2026            0.00             1\n",
      "\n",
      "Records with null/missing year: 8\n",
      "\n",
      "Year range: 2014 - 2026\n",
      "Peak spending year: 2025 ($1142.12B)\n",
      "Most documented year: 2024 (79 records)\n"
     ]
    }
   ],
   "source": [
    "def analyze_temporal_trends():\n",
    "    \"\"\"Analyze spending trends over time\"\"\"\n",
    "    yearly_data = defaultdict(lambda: {'amount': 0, 'count': 0, 'null_year': 0})\n",
    "\n",
    "    for company, domains in mag7_data.items():\n",
    "        for domain, records in domains.items():\n",
    "            for record in records:\n",
    "                year = record.get('year')\n",
    "                amount = record.get('investment_amount_billions_usd')\n",
    "\n",
    "                if year is not None and isinstance(year, int):\n",
    "                    yearly_data[year]['count'] += 1\n",
    "                    if amount is not None and isinstance(amount, (int, float)):\n",
    "                        yearly_data[year]['amount'] += amount\n",
    "                else:\n",
    "                    yearly_data['Unknown']['null_year'] += 1\n",
    "\n",
    "    # Separate years and \"Unknown\" to avoid TypeError in sorting\n",
    "    years = [k for k in yearly_data.keys() if isinstance(k, int)]\n",
    "    rows = []\n",
    "    for year in sorted(years):\n",
    "        stats = yearly_data[year]\n",
    "        rows.append({\n",
    "            'year': year,\n",
    "            'total_billions': round(stats['amount'], 2),\n",
    "            'record_count': stats['count']\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    null_year_count = yearly_data['Unknown']['null_year']\n",
    "    return df, null_year_count\n",
    "\n",
    "df_yearly, null_year_count = analyze_temporal_trends()\n",
    "\n",
    "print(\"\\n=== SPENDING BY YEAR ===\")\n",
    "print(df_yearly.to_string(index=False))\n",
    "print(f\"\\nRecords with null/missing year: {null_year_count}\")\n",
    "\n",
    "if not df_yearly.empty:\n",
    "    print(f\"\\nYear range: {df_yearly['year'].min()} - {df_yearly['year'].max()}\")\n",
    "    print(f\"Peak spending year: {df_yearly.loc[df_yearly['total_billions'].idxmax(), 'year']} (${df_yearly['total_billions'].max():.2f}B)\")\n",
    "    print(f\"Most documented year: {df_yearly.loc[df_yearly['record_count'].idxmax(), 'year']} ({df_yearly['record_count'].max()} records)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4149a214",
   "metadata": {},
   "source": [
    "## 6. Gap Analysis - Missing Data Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4b8b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GAP ANALYSIS ===\n",
      "\n",
      "1. Companies Missing Domains:\n",
      "\n",
      "Alphabet missing 12 domains:\n",
      "  - 5g_6g_network_infrastructure\n",
      "  - digital_health_devices\n",
      "  - edge_computing_infrastructure\n",
      "  - gaming_platforms_engines\n",
      "  - industrial_automation_supply_chain\n",
      "  ... and 7 more\n",
      "\n",
      "Amazon missing 13 domains:\n",
      "  - 5g_6g_network_infrastructure\n",
      "  - bio_ai_and_drug_discovery\n",
      "  - digital_inclusion_and_economy\n",
      "  - gaming_platforms_engines\n",
      "  - litigation_settlements_fines\n",
      "  ... and 8 more\n",
      "\n",
      "Apple missing 9 domains:\n",
      "  - bio_ai_and_drug_discovery\n",
      "  - edge_computing_infrastructure\n",
      "  - industrial_automation_supply_chain\n",
      "  - quantum_computing\n",
      "  - regulatory_compliance_investments\n",
      "  ... and 4 more\n",
      "\n",
      "Meta missing 16 domains:\n",
      "  - 5g_6g_network_infrastructure\n",
      "  - autonomous_mobility\n",
      "  - batteries_and_storage\n",
      "  - bio_ai_and_drug_discovery\n",
      "  - content_production_studios\n",
      "  ... and 11 more\n",
      "\n",
      "Microsoft missing 14 domains:\n",
      "  - bio_ai_and_drug_discovery\n",
      "  - edge_computing_infrastructure\n",
      "  - industrial_automation_supply_chain\n",
      "  - litigation_settlements_fines\n",
      "  - mergers_and_acquisitions\n",
      "  ... and 9 more\n",
      "\n",
      "NVIDIA missing 21 domains:\n",
      "  - 5g_6g_network_infrastructure\n",
      "  - batteries_and_storage\n",
      "  - content_production_studios\n",
      "  - digital_health_devices\n",
      "  - digital_inclusion_and_economy\n",
      "  ... and 16 more\n",
      "\n",
      "Tesla missing 21 domains:\n",
      "  - 5g_6g_network_infrastructure\n",
      "  - ai_foundation_models\n",
      "  - bio_ai_and_drug_discovery\n",
      "  - content_production_studios\n",
      "  - digital_health_devices\n",
      "  ... and 16 more\n",
      "\n",
      "2. Domains with NO Documented Amounts (All Null):\n",
      "  - superconducting_devices_squids: 1 records, companies: Alphabet\n",
      "\n",
      "3. Domains with Few Companies (<= 2):\n",
      "  - superconducting_devices_squids: 1 companies (Alphabet)\n",
      "  - wellness_vr_and_behavioral: 1 companies (Meta)\n",
      "  - regulatory_compliance_investments: 1 companies (Meta)\n",
      "  - edge_computing_infrastructure: 1 companies (Amazon)\n",
      "  - r_and_d: 1 companies (Apple)\n",
      "  - supply_chain_digitization: 1 companies (Apple)\n",
      "  - sci_fi_consumer_devices: 2 companies (Amazon, Meta)\n",
      "  - 5g_6g_network_infrastructure: 2 companies (Apple, Microsoft)\n",
      "  - gaming_platforms_engines: 2 companies (Apple, Microsoft)\n",
      "  - mergers_and_acquisitions: 2 companies (Apple, Alphabet)\n",
      "\n",
      "4. Domain-Company Combinations with High Null Rates (>50%):\n",
      "  - superconducting_devices_squids: 100.0% null (1 records)\n",
      "  - renewable_energy_generation: 79.7% null (59 records)\n",
      "  - responsible_ai_safety_governance: 66.7% null (3 records)\n",
      "  - security_cryptography: 57.1% null (7 records)\n",
      "  - circularity_reuse_recycling: 54.5% null (11 records)\n",
      "  - ai_efficiency_methods: 54.5% null (11 records)\n"
     ]
    }
   ],
   "source": [
    "def identify_gaps():\n",
    "    \"\"\"Identify gaps in data coverage\"\"\"\n",
    "    gaps = {\n",
    "        'companies_missing_domains': defaultdict(list),\n",
    "        'domains_with_no_amounts': [],\n",
    "        'domains_with_few_companies': [],\n",
    "        'high_null_rate_combinations': []\n",
    "    }\n",
    "    \n",
    "    # Check which companies are missing which domains\n",
    "    for company in mag7_data.keys():\n",
    "        company_domains = set(mag7_data[company].keys())\n",
    "        missing = all_domains - company_domains\n",
    "        if missing:\n",
    "            gaps['companies_missing_domains'][company] = sorted(missing)\n",
    "    \n",
    "    # Check domains with no documented amounts\n",
    "    for domain in all_domains:\n",
    "        total_amount = 0\n",
    "        total_records = 0\n",
    "        null_count = 0\n",
    "        companies_with_domain = []\n",
    "        \n",
    "        for company, domains in mag7_data.items():\n",
    "            if domain in domains:\n",
    "                companies_with_domain.append(company)\n",
    "                for record in domains[domain]:\n",
    "                    total_records += 1\n",
    "                    amount = record.get('investment_amount_billions_usd')\n",
    "                    if amount is not None and isinstance(amount, (int, float)):\n",
    "                        total_amount += amount\n",
    "                    else:\n",
    "                        null_count += 1\n",
    "        \n",
    "        if total_amount == 0 and total_records > 0:\n",
    "            gaps['domains_with_no_amounts'].append({\n",
    "                'domain': domain,\n",
    "                'record_count': total_records,\n",
    "                'companies': companies_with_domain\n",
    "            })\n",
    "        \n",
    "        if len(companies_with_domain) <= 2 and len(companies_with_domain) > 0:\n",
    "            gaps['domains_with_few_companies'].append({\n",
    "                'domain': domain,\n",
    "                'company_count': len(companies_with_domain),\n",
    "                'companies': companies_with_domain\n",
    "            })\n",
    "        \n",
    "        # High null rate (>50%)\n",
    "        if total_records > 0 and (null_count / total_records) > 0.5:\n",
    "            gaps['high_null_rate_combinations'].append({\n",
    "                'domain': domain,\n",
    "                'null_rate': round(null_count / total_records * 100, 1),\n",
    "                'total_records': total_records\n",
    "            })\n",
    "    \n",
    "    return gaps\n",
    "\n",
    "gaps = identify_gaps()\n",
    "\n",
    "print(\"\\n=== GAP ANALYSIS ===\")\n",
    "\n",
    "print(\"\\n1. Companies Missing Domains:\")\n",
    "for company, missing_domains in sorted(gaps['companies_missing_domains'].items()):\n",
    "    print(f\"\\n{company} missing {len(missing_domains)} domains:\")\n",
    "    for domain in missing_domains[:5]:\n",
    "        print(f\"  - {domain}\")\n",
    "    if len(missing_domains) > 5:\n",
    "        print(f\"  ... and {len(missing_domains) - 5} more\")\n",
    "\n",
    "print(\"\\n2. Domains with NO Documented Amounts (All Null):\")\n",
    "for item in gaps['domains_with_no_amounts'][:10]:\n",
    "    print(f\"  - {item['domain']}: {item['record_count']} records, companies: {', '.join(item['companies'])}\")\n",
    "\n",
    "print(\"\\n3. Domains with Few Companies (<= 2):\")\n",
    "for item in sorted(gaps['domains_with_few_companies'], key=lambda x: x['company_count'])[:10]:\n",
    "    print(f\"  - {item['domain']}: {item['company_count']} companies ({', '.join(item['companies'])})\")\n",
    "\n",
    "print(\"\\n4. Domain-Company Combinations with High Null Rates (>50%):\")\n",
    "for item in sorted(gaps['high_null_rate_combinations'], key=lambda x: x['null_rate'], reverse=True)[:15]:\n",
    "    print(f\"  - {item['domain']}: {item['null_rate']}% null ({item['total_records']} records)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd11be5",
   "metadata": {},
   "source": [
    "## 10. Domain Coverage Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e6d87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DOMAIN COVERAGE MATRIX ===\n",
      "Format: (records_with_amount / total_records)\n",
      "\n",
      "                             domain Alphabet Amazon Apple  Meta Microsoft NVIDIA Tesla\n",
      "       5g_6g_network_infrastructure      0/0    0/0   1/1   0/0       1/1    0/0   0/0\n",
      "              ai_efficiency_methods      1/2    1/1   0/2   0/1       0/1    1/2   2/2\n",
      "               ai_foundation_models      1/1    2/2   1/2   1/2       9/9    9/9   0/0\n",
      "                autonomous_mobility      4/4    1/1   2/2   0/0       1/1    2/2   3/3\n",
      "              batteries_and_storage      1/2    2/2   0/1   0/0       1/1    0/0   7/8\n",
      "          bio_ai_and_drug_discovery      1/1    0/0   0/0   0/0       0/0    2/2   0/0\n",
      "        circularity_reuse_recycling      0/2    2/2   0/1   0/2       1/1    2/2   0/1\n",
      "        cloud_data_centers_ai_infra      5/6    7/7   2/2   3/3       7/7    8/9   2/2\n",
      "         content_production_studios      1/1    2/2   3/4   0/0       1/1    0/0   0/0\n",
      "             digital_health_devices      0/0    1/1   0/1   0/0       1/1    0/0   0/0\n",
      "      digital_inclusion_and_economy      2/2    0/0   2/2   2/2       3/3    0/0   1/1\n",
      "         diversity_equity_inclusion      1/1    1/1   1/1   1/1       1/1    0/0   0/1\n",
      "      edge_computing_infrastructure      0/0    1/1   0/0   0/0       0/0    0/0   0/0\n",
      "           gaming_platforms_engines      0/0    0/0   0/1   0/0       3/3    0/0   0/0\n",
      " industrial_automation_supply_chain      0/0    2/2   0/0   0/0       0/0    3/3   2/3\n",
      "       litigation_settlements_fines      6/6    0/0   1/1   3/3       0/0    0/0   1/1\n",
      "           mergers_and_acquisitions      1/1    0/0   2/2   0/0       0/0    0/0   0/0\n",
      "                  quantum_computing      0/1    1/2   0/0   0/0       1/1    1/1   0/0\n",
      "                            r_and_d      0/0    0/0   0/0   0/0       0/0    0/0   0/0\n",
      "  regulatory_compliance_investments      0/0    0/0   0/0   1/1       0/0    0/0   0/0\n",
      "        renewable_energy_generation     3/11   1/12   2/9   2/6      2/13    0/2   2/6\n",
      "   responsible_ai_safety_governance      0/0    0/0   0/0   1/2       0/1    0/0   0/0\n",
      "                  robotics_autonomy      2/2    2/2   0/1   0/1       1/1    1/2   0/1\n",
      "satellite_and_subsea_infrastructure      1/2    4/4   2/2   2/2       0/0    0/0   0/0\n",
      "            sci_fi_consumer_devices      0/0    1/2   0/0   1/1       0/0    0/0   0/0\n",
      "              security_cryptography      2/2    0/1   0/1   0/1       1/1    0/1   0/0\n",
      "          semiconductor_ai_hardware      1/1    2/2   2/2   0/1       3/3    1/1   0/0\n",
      "                  share_repurchases    12/12    4/4 11/11 10/10     12/12    8/8   3/3\n",
      "              strategic_investments      2/3    6/7   3/3   0/0       0/0    0/0   0/0\n",
      "     superconducting_devices_squids      0/1    0/0   0/0   0/0       0/0    0/0   0/0\n",
      "          supply_chain_digitization      0/0    0/0   2/2   0/0       0/0    0/0   0/0\n",
      "         wellness_vr_and_behavioral      0/0    0/0   0/0   1/1       0/0    0/0   0/0\n",
      "      workforce_training_reskilling      0/0    1/1   2/2   0/0       1/1    0/0   0/0\n",
      " xr_metaverse_and_spatial_computing      0/1    0/0   2/2   7/7       0/0    0/0   0/0\n"
     ]
    }
   ],
   "source": [
    "def create_coverage_matrix():\n",
    "    \"\"\"Create a matrix showing which companies have data in which domains\"\"\"\n",
    "    matrix_data = []\n",
    "    \n",
    "    for domain in sorted(all_domains):\n",
    "        row = {'domain': domain}\n",
    "        for company in sorted(mag7_data.keys()):\n",
    "            if domain in mag7_data[company]:\n",
    "                record_count = len(mag7_data[company][domain])\n",
    "                # Count how many have amounts\n",
    "                with_amount = sum(1 for r in mag7_data[company][domain] \n",
    "                                if r.get('investment_amount_billions_usd') is not None)\n",
    "                row[company] = f\"{with_amount}/{record_count}\"\n",
    "            else:\n",
    "                row[company] = \"0/0\"\n",
    "        matrix_data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(matrix_data)\n",
    "\n",
    "df_coverage = create_coverage_matrix()\n",
    "\n",
    "print(\"\\n=== DOMAIN COVERAGE MATRIX ===\")\n",
    "print(\"Format: (records_with_amount / total_records)\\n\")\n",
    "print(df_coverage.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf345a",
   "metadata": {},
   "source": [
    "## 11. Research Priority Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e14da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESEARCH PRIORITY RECOMMENDATIONS ===\n",
      "\n",
      "HIGH PRIORITY (High activity domains with low documentation):\n",
      "                     domain  records  doc_rate                             action\n",
      "renewable_energy_generation     59.0      20.3 Find dollar amounts for 47 records\n",
      "      security_cryptography      7.0      42.9  Find dollar amounts for 4 records\n",
      "      ai_efficiency_methods     11.0      45.5  Find dollar amounts for 6 records\n",
      "circularity_reuse_recycling     11.0      45.5  Find dollar amounts for 6 records\n",
      "\n",
      "MEDIUM PRIORITY (Companies missing many domains):\n",
      "  company                domain                                                                                                                            action\n",
      "Microsoft Multiple (14 domains) Research Microsoft's activity in: bio_ai_and_drug_discovery, edge_computing_infrastructure, industrial_automation_supply_chain...\n",
      " Alphabet Multiple (12 domains)           Research Alphabet's activity in: 5g_6g_network_infrastructure, digital_health_devices, edge_computing_infrastructure...\n",
      "   Amazon Multiple (13 domains)          Research Amazon's activity in: 5g_6g_network_infrastructure, bio_ai_and_drug_discovery, digital_inclusion_and_economy...\n",
      "   NVIDIA Multiple (21 domains)                 Research NVIDIA's activity in: 5g_6g_network_infrastructure, batteries_and_storage, content_production_studios...\n",
      "    Tesla Multiple (21 domains)                    Research Tesla's activity in: 5g_6g_network_infrastructure, ai_foundation_models, bio_ai_and_drug_discovery...\n",
      "     Meta Multiple (16 domains)                          Research Meta's activity in: 5g_6g_network_infrastructure, autonomous_mobility, batteries_and_storage...\n",
      "\n",
      "LOW PRIORITY (Single-company domains):\n",
      "                           domain                                               action\n",
      "   superconducting_devices_squids    Check if NVIDIA, Apple, Amazon have activity here\n",
      "       wellness_vr_and_behavioral  Check if Alphabet, NVIDIA, Apple have activity here\n",
      "regulatory_compliance_investments  Check if Alphabet, NVIDIA, Apple have activity here\n",
      "    edge_computing_infrastructure  Check if Alphabet, NVIDIA, Apple have activity here\n",
      "                          r_and_d Check if Alphabet, NVIDIA, Amazon have activity here\n",
      "        supply_chain_digitization Check if Alphabet, NVIDIA, Amazon have activity here\n"
     ]
    }
   ],
   "source": [
    "def generate_research_priorities():\n",
    "    \"\"\"Generate prioritized list of areas needing more research\"\"\"\n",
    "    priorities = []\n",
    "    \n",
    "    # Priority 1: Domains with high activity but low documentation\n",
    "    for _, row in df_domain_spending.iterrows():\n",
    "        if row['total_records'] >= 5 and row['documentation_rate'] < 50:\n",
    "            priorities.append({\n",
    "                'priority': 'HIGH',\n",
    "                'reason': 'High activity, low documentation',\n",
    "                'domain': row['domain'],\n",
    "                'records': row['total_records'],\n",
    "                'doc_rate': row['documentation_rate'],\n",
    "                'action': f\"Find dollar amounts for {row['null_amount']} records\"\n",
    "            })\n",
    "    \n",
    "    # Priority 2: Major companies missing entire domains\n",
    "    for company, missing in gaps['companies_missing_domains'].items():\n",
    "        if len(missing) > 10:\n",
    "            priorities.append({\n",
    "                'priority': 'MEDIUM',\n",
    "                'reason': 'Company missing many domains',\n",
    "                'domain': f\"Multiple ({len(missing)} domains)\",\n",
    "                'company': company,\n",
    "                'action': f\"Research {company}'s activity in: {', '.join(list(missing)[:3])}...\"\n",
    "            })\n",
    "    \n",
    "    # Priority 3: Domains with only 1-2 companies (potential gaps)\n",
    "    for item in gaps['domains_with_few_companies']:\n",
    "        if item['company_count'] == 1:\n",
    "            missing_companies = set(mag7_data.keys()) - set(item['companies'])\n",
    "            priorities.append({\n",
    "                'priority': 'LOW',\n",
    "                'reason': 'Only 1 company in domain',\n",
    "                'domain': item['domain'],\n",
    "                'action': f\"Check if {', '.join(list(missing_companies)[:3])} have activity here\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(priorities)\n",
    "\n",
    "df_priorities = generate_research_priorities()\n",
    "\n",
    "print(\"\\n=== RESEARCH PRIORITY RECOMMENDATIONS ===\")\n",
    "print(\"\\nHIGH PRIORITY (High activity domains with low documentation):\")\n",
    "high_pri = df_priorities[df_priorities['priority'] == 'HIGH']\n",
    "if not high_pri.empty:\n",
    "    print(high_pri[['domain', 'records', 'doc_rate', 'action']].to_string(index=False))\n",
    "\n",
    "print(\"\\nMEDIUM PRIORITY (Companies missing many domains):\")\n",
    "med_pri = df_priorities[df_priorities['priority'] == 'MEDIUM']\n",
    "if not med_pri.empty:\n",
    "    print(med_pri[['company', 'domain', 'action']].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nLOW PRIORITY (Single-company domains):\")\n",
    "low_pri = df_priorities[df_priorities['priority'] == 'LOW']\n",
    "if not low_pri.empty:\n",
    "    print(low_pri[['domain', 'action']].head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a544fc6d",
   "metadata": {},
   "source": [
    "## 12. Save All Results to File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd764799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Analysis complete! Results saved to: mag7_analysis_summary_20251202_165728.txt\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive summary report\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f\"mag7_analysis_summary_{timestamp}.txt\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"MAG7 SPENDING DATA - COMPREHENSIVE ANALYSIS SUMMARY\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"EXECUTIVE SUMMARY\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"Total Companies: {len(mag7_data)}\\n\")\n",
    "    f.write(f\"Total Domains: {len(all_domains)}\\n\")\n",
    "    f.write(f\"Total Records: {sum(record_counts.values())}\\n\")\n",
    "    f.write(f\"Total Documented Spending: ${df_company_spending['total_billions'].sum():.2f}B\\n\")\n",
    "    f.write(f\"Average Documentation Rate: {df_company_spending['percent_documented'].mean():.1f}%\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"1. SPENDING BY COMPANY\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(df_company_spending.to_string())\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"2. TOP 20 DOMAINS BY SPENDING\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(df_domain_spending.head(20).to_string(index=False))\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"3. SPENDING BY TYPE (AGGREGATE)\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(type_totals.to_string())\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"4. SPENDING BY YEAR\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(df_yearly.to_string(index=False))\n",
    "    f.write(f\"\\nRecords with missing year: {null_year_count}\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"5. DOMAIN COVERAGE MATRIX\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(\"Format: (records_with_amount / total_records)\\n\\n\")\n",
    "    f.write(df_coverage.to_string(index=False))\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"6. GAP ANALYSIS - MISSING DATA IDENTIFICATION\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    for item in gaps['domains_with_no_amounts']:\n",
    "        f.write(f\"  - {item['domain']}: {item['record_count']} records\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"7. CAPEX TYPE & TECH BREAKDOWN (BY COMPANY)\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    for company, df_capex in company_capex_breakdowns.items():\n",
    "        if not df_capex.empty:\n",
    "            f.write(f\"\\n{company}:\\n\")\n",
    "            f.write(df_capex.to_string(index=False) + \"\\n\")\n",
    "        else:\n",
    "            f.write(f\"\\n{company}: No capex records found.\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"8. CAPEX TYPE TOTALS (ROLLUPS)\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    if not df_capex_type_totals.empty:\n",
    "        f.write(df_capex_type_totals.to_string(index=False))\n",
    "    else:\n",
    "        f.write(\"No aggregated capex totals available.\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"9. OPEX TYPE BREAKDOWN (BY COMPANY)\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    for company, df_opex in ope_capex_breakdowns.items():\n",
    "        if not df_opex.empty:\n",
    "            f.write(f\"\\n{company}:\\n\")\n",
    "            f.write(df_opex.to_string(index=False) + \"\\n\")\n",
    "        else:\n",
    "            f.write(f\"\\n{company}: No opex records found.\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"10. OPEX TYPE TOTALS\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    if not df_opex_type_totals.empty:\n",
    "        f.write(df_opex_type_totals.to_string(index=False))\n",
    "    else:\n",
    "        f.write(\"No aggregated opex totals available.\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"11. RESEARCH PRIORITY RECOMMENDATIONS\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    if not df_priorities.empty:\n",
    "        f.write(df_priorities.to_string(index=False) + \"\\n\")\n",
    "    else:\n",
    "        f.write(\"No specific research priorities identified based on current criteria.\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "\n",
    "print(f\"\\n Analysis complete! Results saved to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
